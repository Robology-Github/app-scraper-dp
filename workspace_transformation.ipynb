{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "appstore_df = pd.read_csv('./AppStoreOutput_cleaned.csv')\n",
    "googleplay_df = pd.read_csv('./GooglePlayOutput_cleaned.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(\"App Store Data Info:\")\n",
    "print(appstore_df.info())\n",
    "\n",
    "print(\"\\nGoogle Play Store Data Info:\")\n",
    "print(googleplay_df.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords already installed.\n",
      "Empty DataFrame\n",
      "Columns: [Language, Number of Apps]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Genre, Number of Apps]\n",
      "Index: []\n",
      "  Device Type  Number of Apps\n",
      "0      iPhone              20\n",
      "1        iPad              20\n",
      "2         Mac               1\n",
      "Bigrams and word frequencies have been saved to CSV files.\n",
      "                              appId                           title  \\\n",
      "0                 com.wanderlog.ios      Wanderlog - Travel Planner   \n",
      "1           com.tripit.tripitmobile          TripIt: Travel Planner   \n",
      "2                    app.tripsy.ios  Tripsy: Travel Planner & Guide   \n",
      "3  com.roadtrippers.roadtrippersinc     Roadtrippers - Trip Planner   \n",
      "4        com.tripadvisor.LocalPicks  Tripadvisor: Plan & Book Trips   \n",
      "\n",
      "                                                 url primaryGenre  \\\n",
      "0  https://apps.apple.com/us/app/wanderlog-travel...       Travel   \n",
      "1  https://apps.apple.com/us/app/tripit-travel-pl...       Travel   \n",
      "2  https://apps.apple.com/us/app/tripsy-travel-pl...       Travel   \n",
      "3  https://apps.apple.com/us/app/roadtrippers-tri...       Travel   \n",
      "4  https://apps.apple.com/us/app/tripadvisor-plan...       Travel   \n",
      "\n",
      "  contentRating       size                  released  \\\n",
      "0            4+  106180608 2019-08-22 07:00:00+00:00   \n",
      "1            4+  137182208 2009-04-10 22:18:20+00:00   \n",
      "2            4+  131228672 2018-10-26 02:58:32+00:00   \n",
      "3            4+  171893760 2014-11-25 13:10:20+00:00   \n",
      "4            4+  172310528 2019-02-05 08:00:00+00:00   \n",
      "\n",
      "                    updated  price  free  ... days_since_last_update app_age  \\\n",
      "0 2024-04-11 22:31:17+00:00      0  free  ...                     15    1694   \n",
      "1 2024-03-25 16:37:58+00:00      0  free  ...                     33    5462   \n",
      "2 2024-04-23 13:40:20+00:00      0  free  ...                      4    2006   \n",
      "3 2024-04-18 15:33:14+00:00      0  free  ...                      9    3432   \n",
      "4 2024-04-24 13:07:55+00:00      0  free  ...                      3    1905   \n",
      "\n",
      "                                   processed_reviews  \\\n",
      "0  may useful app quite annoying every thing clic...   \n",
      "1  used app everyone knew schedule day easy use e...   \n",
      "2  pro premium well worth currently trips planned...   \n",
      "3  clue site offers paid package allows plan trip...   \n",
      "4  julia absolute amazing tour guy enjoyed every ...   \n",
      "\n",
      "                                         bigram_freq  \\\n",
      "0  [(may useful, 1), (useful app, 3), (app quite,...   \n",
      "1  [(used app, 5), (app everyone, 1), (everyone k...   \n",
      "2  [(pro premium, 1), (premium well, 1), (well wo...   \n",
      "3  [(clue site, 1), (site offers, 1), (offers pai...   \n",
      "4  [(julia absolute, 1), (absolute amazing, 1), (...   \n",
      "\n",
      "                                           word_freq  Sentiment_Category  \\\n",
      "0  [(may, 1), (useful, 7), (app, 59), (quite, 2),...   Slightly negative   \n",
      "1  [(used, 7), (app, 52), (everyone, 3), (knew, 1...            Positive   \n",
      "2  [(pro, 6), (premium, 2), (well, 7), (worth, 8)...            Positive   \n",
      "3  [(clue, 1), (site, 1), (offers, 1), (paid, 7),...            Negative   \n",
      "4  [(julia, 1), (absolute, 1), (amazing, 8), (tou...   Slightly positive   \n",
      "\n",
      "      update_frequency  price_category  app_age_category  file_size_category  \n",
      "0  Very Recent Updates            Free       Very Mature              Medium  \n",
      "1     Recently Updated            Free       Very Mature              Medium  \n",
      "2  Very Recent Updates            Free       Very Mature              Medium  \n",
      "3  Very Recent Updates            Free       Very Mature              Medium  \n",
      "4  Very Recent Updates            Free       Very Mature              Medium  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from iso639 import languages\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "import os    \n",
    "\n",
    "\n",
    "df = pd.read_csv('./AppStoreOutput.csv', delimiter=',', encoding='utf-8')\n",
    "df['released'] = pd.to_datetime(df['released'])\n",
    "df['updated'] = pd.to_datetime(df['updated'])\n",
    "df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
    "df['free'] = df['free'].astype(int)\n",
    "df['supports_iPhone'] = 0\n",
    "df['supports_iPad'] = 0\n",
    "df['supports_Mac'] = 0\n",
    "df['days_since_last_update'] = (datetime.now(timezone.utc) - df['updated']).dt.days\n",
    "df['app_age'] = (df['updated'] - df['released']).dt.days\n",
    "df['reviews'] = df['reviews'].astype(str)\n",
    "\n",
    "# Load the sentiment analysis pipeline with the multilingual BERT model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "\n",
    "# Function to ensure stopwords are available\n",
    "def ensure_stopwords():\n",
    "# Define the default path (adjust as needed for your system)\n",
    "    default_path = os.path.join(nltk.data.path[0], 'corpora', 'stopwords')\n",
    "    if not os.path.exists(default_path):\n",
    "        print(\"Downloading NLTK stopwords...\")\n",
    "        nltk.download('stopwords')\n",
    "    else:\n",
    "        print(\"Stopwords already installed.\")\n",
    "\n",
    "ensure_stopwords()\n",
    "\n",
    "\n",
    "# Mapping from language names to NLTK compatible language codes\n",
    "nltk_lang_map = {\n",
    "    'ar': 'arabic',\n",
    "    'az': 'azerbaijani',\n",
    "    'eu': 'basque',\n",
    "    'bn': 'bengali',\n",
    "    'ca': 'catalan',\n",
    "    'zh': 'chinese',\n",
    "    'da': 'danish',\n",
    "    'nl': 'dutch',\n",
    "    'en': 'english',\n",
    "    'fi': 'finnish',\n",
    "    'fr': 'french',\n",
    "    'de': 'german',\n",
    "    'el': 'greek',\n",
    "    'he': 'hebrew',\n",
    "    'hu': 'hungarian',\n",
    "    'id': 'indonesian',\n",
    "    'it': 'italian',\n",
    "    'kk': None,  # No support in NLTK\n",
    "    'ne': None,  # No support in NLTK\n",
    "    'no': 'norwegian',\n",
    "    'pt': 'portuguese',\n",
    "    'ro': 'romanian',\n",
    "    'ru': 'russian',\n",
    "    'sl': 'slovene',\n",
    "    'es': 'spanish',\n",
    "    'sv': 'swedish',\n",
    "    'tg': None,  # No support in NLTK\n",
    "    'tr': 'turkish'\n",
    "}\n",
    "\n",
    "def get_stopwords(text):\n",
    "    try:\n",
    "        # Detect the language of the text\n",
    "        lang = detect(text)\n",
    "        # Get the stopwords for the detected language\n",
    "        stopwords_lang = nltk_lang_map.get(lang, 'english')\n",
    "        if stopwords_lang:\n",
    "            return set(stopwords.words(stopwords_lang))\n",
    "        else:\n",
    "            return set(stopwords.words('english'))\n",
    "    except Exception as e:\n",
    "        print(\"Error in detecting language or loading stopwords:\", e)\n",
    "        return set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_and_split_reviews(reviews):\n",
    "    # Convert reviews to string to avoid TypeError with non-string inputs\n",
    "    if pd.isna(reviews):\n",
    "        return \"\"  # Return an empty string if the review is NaN\n",
    "    reviews = str(reviews)\n",
    "    try:\n",
    "        # Use language-specific stopwords\n",
    "        stop_words = get_stopwords(reviews)\n",
    "    except Exception as e:\n",
    "        print(\"Error using language-specific stopwords:\", e)\n",
    "        stop_words = set(stopwords.words('english'))  # Default to English if error occurs\n",
    "\n",
    "    # Remove all non-alpha characters and extra spaces, convert to lower case\n",
    "    reviews = re.sub(r'[^\\\\wáčďéěíňóřšťúůýžÁČĎÉĚÍŇÓŘŠŤÚŮÝŽ]', ' ', reviews, flags=re.UNICODE)\n",
    "    reviews = re.sub('\\\\s+', ' ', reviews).strip().lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in reviews.split() if word not in stop_words and len(word) > 1]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the modified function to your DataFrame\n",
    "df['processed_reviews'] = df['reviews'].apply(preprocess_and_split_reviews)\n",
    "\n",
    "def get_and_flatten_bigrams(text):\n",
    "    if len(text.split()) < 2:\n",
    "        return []\n",
    "    blob = TextBlob(text)\n",
    "    bigrams = [' '.join(bigram) for bigram in blob.ngrams(2)]\n",
    "    # Count bigrams\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    # Return bigrams with their frequencies\n",
    "    return list(bigram_counts.items())\n",
    "\n",
    "# Apply the function\n",
    "df['bigram_freq'] = df['processed_reviews'].apply(get_and_flatten_bigrams)\n",
    "bigram_freq_rows = df.explode('bigram_freq')\n",
    "\n",
    "# Create a new DataFrame that splits the bigram and frequency into separate columns\n",
    "bigram_freq_df = pd.DataFrame({\n",
    "    'appId': bigram_freq_rows['appId'],\n",
    "    'bigrams': bigram_freq_rows['bigram_freq'].apply(lambda x: x[0] if pd.notna(x) else ''),\n",
    "    'frequency': bigram_freq_rows['bigram_freq'].apply(lambda x: x[1] if pd.notna(x) else 0)\n",
    "}).dropna()\n",
    "\n",
    "def flatten_word_frequencies(text):\n",
    "    words = text.split()\n",
    "    freqs = Counter(words)\n",
    "    # Get all word frequencies, without limiting to top 20\n",
    "    return list(freqs.items())\n",
    "\n",
    "# Apply the  function\n",
    "df['word_freq'] = df['processed_reviews'].apply(flatten_word_frequencies)\n",
    "word_freq_rows = df.explode('word_freq')\n",
    "word_freq_df = pd.DataFrame({\n",
    "    'appId': word_freq_rows['appId'],\n",
    "    'word': word_freq_rows['word_freq'].apply(lambda x: x[0] if pd.notna(x) else ''),\n",
    "    'frequency': word_freq_rows['word_freq'].apply(lambda x: x[1] if pd.notna(x) else 0)\n",
    "}).dropna()\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if 'iPhone' in row['supportedDevices']:\n",
    "        df.at[index, 'supports_iPhone'] = 1\n",
    "    if 'iPad' in row['supportedDevices']:\n",
    "        df.at[index, 'supports_iPad'] = 1\n",
    "    if 'Mac' in row['supportedDevices']:\n",
    "        df.at[index, 'supports_Mac'] = 1\n",
    "\n",
    "\n",
    "\n",
    "def compute_sentiment_category_mbert(text):\n",
    "    try:\n",
    "        # Directly pass the text to the pipeline\n",
    "        # The pipeline handles tokenization and truncation internally\n",
    "        result = sentiment_analyzer(text, truncation=True, max_length=512)[0]\n",
    "        label = result['label']\n",
    "        \n",
    "        # Mapping the model output to custom categories\n",
    "        if label == '1 star':\n",
    "            return 'Negative'\n",
    "        elif label == '2 stars':\n",
    "            return 'Slightly negative'\n",
    "        elif label == '3 stars':\n",
    "            return 'Neutral'\n",
    "        elif label == '4 stars':\n",
    "            return 'Slightly positive'\n",
    "        else:  # '5 stars'\n",
    "            return 'Positive'\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return 'Missing'  # Default to 'Missing' in case of an error\n",
    "\n",
    "df['Sentiment_Category'] = df['processed_reviews'].apply(compute_sentiment_category_mbert)\n",
    "\n",
    "\n",
    "# Parsing and One-hot Encoding for List Columns\n",
    "def parse_list_column(column):\n",
    "    try:\n",
    "        return column.apply(literal_eval)\n",
    "    except ValueError:\n",
    "        return column\n",
    "\n",
    "df['languages'] = parse_list_column(df['languages'])\n",
    "df['genres'] = parse_list_column(df['genres'])\n",
    "\n",
    "languages_exploded = df[['appId', 'languages']].explode('languages')\n",
    "genres_exploded = df[['appId', 'genres']].explode('genres')\n",
    "\n",
    "\n",
    "# Expanded Language-to-Countries Mapping\n",
    "language_to_countries = {\n",
    "    'AF': ['Afghanistan'],\n",
    "    'AM': ['Armenia'],\n",
    "    'AN': ['Netherlands Antilles'],\n",
    "    'AR': ['Saudi Arabia', 'Iraq', 'Egypt', 'Algeria', 'Morocco', 'Sudan', 'Yemen', 'Syria', 'Tunisia', 'Jordan', 'Libya', 'Lebanon', 'Oman', 'Kuwait', 'Mauritania', 'Qatar', 'Bahrain', 'United Arab Emirates'],\n",
    "    'AZ': ['Azerbaijan'],\n",
    "    'BE': ['Belarus'],\n",
    "    'BG': ['Bulgaria'],\n",
    "    'BN': ['Bangladesh', 'India'],\n",
    "    'BR': ['Brazil'],\n",
    "    'BS': ['Bosnia and Herzegovina'],\n",
    "    'CA': ['Spain', 'Andorra'],\n",
    "    'CO': ['France'],\n",
    "    'CS': ['Czech Republic'],\n",
    "    'CY': ['Wales'],\n",
    "    'DA': ['Denmark', 'Greenland', 'Faroe Islands'],\n",
    "    'DE': ['Germany', 'Austria', 'Switzerland', 'Luxembourg', 'Liechtenstein'],\n",
    "    'EL': ['Greece', 'Cyprus'],\n",
    "    'EN': ['United States', 'United Kingdom', 'Canada', 'Australia', 'Ireland', 'New Zealand', 'South Africa'],\n",
    "    'EO': ['Worldwide'],  # Esperanto is a constructed international auxiliary language.\n",
    "    'ES': ['Spain', 'Mexico', 'Colombia', 'Argentina', 'Peru', 'Venezuela', 'Chile', 'Ecuador', 'Guatemala', 'Cuba', 'Bolivia', 'Dominican Republic', 'Honduras', 'Paraguay', 'El Salvador', 'Nicaragua', 'Costa Rica', 'Puerto Rico', 'Panama', 'Uruguay'],\n",
    "    'ET': ['Estonia'],\n",
    "    'EU': ['Spain'],  # Basque Country\n",
    "    'FA': ['Iran', 'Afghanistan', 'Tajikistan'],\n",
    "    'FI': ['Finland', 'Sweden'],\n",
    "    'FR': ['France', 'Canada', 'Belgium', 'Switzerland', 'Luxembourg', 'Monaco', 'Congo', 'Ivory Coast', 'Madagascar', 'Cameroon', 'Burkina Faso', 'Niger', 'Senegal', 'Mali', 'Rwanda', 'Belgium', 'Guinea'],\n",
    "    'FY': ['Netherlands'],\n",
    "    'GA': ['Ireland'],\n",
    "    'GD': ['Scotland'],\n",
    "    'GL': ['Spain'],\n",
    "    'GU': ['India'],\n",
    "    'HE': ['Israel'],\n",
    "    'HI': ['India'],\n",
    "    'HR': ['Croatia', 'Bosnia and Herzegovina'],\n",
    "    'HT': ['Haiti'],\n",
    "    'HU': ['Hungary'],\n",
    "    'HY': ['Armenia', 'Nagorno-Karabakh Republic'],\n",
    "    'IA': ['Worldwide'],  # Interlingua is a constructed international auxiliary language.\n",
    "    'ID': ['Indonesia'],\n",
    "    'IG': ['Nigeria'],\n",
    "    'IS': ['Iceland'],\n",
    "    'IT': ['Italy', 'Switzerland', 'San Marino', 'Vatican City'],\n",
    "    'JA': ['Japan'],\n",
    "    'KA': ['Georgia'],\n",
    "    'KK': ['Kazakhstan'],\n",
    "    'KM': ['Cambodia'],\n",
    "    'KN': ['India'],\n",
    "    'KO': ['South Korea', 'North Korea'],\n",
    "    'KU': ['Turkey', 'Iraq', 'Iran', 'Syria'],\n",
    "    'KY': ['Kyrgyzstan'],\n",
    "    'LO': ['Laos'],\n",
    "    'LT': ['Lithuania'],\n",
    "    'LV': ['Latvia'],\n",
    "    'MK': ['North Macedonia'],\n",
    "    'ML': ['India', 'Sri Lanka'],\n",
    "    'MN': ['Mongolia'],\n",
    "    'MR': ['India'],\n",
    "    'MS': ['Malaysia', 'Brunei', 'Singapore'],\n",
    "    'MT': ['Malta'],\n",
    "    'MY': ['Myanmar'],\n",
    "    'NB': ['Norway'],\n",
    "    'NE': ['Niger'],\n",
    "    'NL': ['Netherlands', 'Belgium', 'Suriname'],\n",
    "    'NN': ['Norway'],\n",
    "    'OC': ['France'],\n",
    "    'PA': ['India', 'Pakistan'],\n",
    "    'PL': ['Poland'],\n",
    "    'PS': ['Afghanistan', 'Pakistan'],\n",
    "    'PT': ['Portugal', 'Brazil', 'Angola', 'Mozambique', 'Cape Verde', 'Guinea-Bissau', 'São Tomé and Príncipe', 'East Timor'],\n",
    "    'RO': ['Romania', 'Moldova'],\n",
    "    'RU': ['Russia', 'Belarus', 'Kazakhstan', 'Kyrgyzstan'],\n",
    "    'SC': ['Italy'],\n",
    "    'SE': ['Sweden'],\n",
    "    'SI': ['Sri Lanka'],\n",
    "    'SK': ['Slovakia'],\n",
    "    'SL': ['Slovenia'],\n",
    "    'SN': ['Zimbabwe'],\n",
    "    'SQ': ['Albania', 'Kosovo'],\n",
    "    'SR': ['Serbia', 'Bosnia and Herzegovina', 'Montenegro', 'Kosovo'],\n",
    "    'SV': ['Sweden'],\n",
    "    'SW': ['Tanzania', 'Kenya', 'Uganda'],\n",
    "    'TA': ['India', 'Sri Lanka'],\n",
    "    'TE': ['India'],\n",
    "    'TG': ['Tajikistan'],\n",
    "    'TH': ['Thailand'],\n",
    "    'TL': ['Timor-Leste'],\n",
    "    'TR': ['Turkey', 'Cyprus'],\n",
    "    'TT': ['Russia'],\n",
    "    'UK': ['Ukraine'],\n",
    "    'UR': ['Pakistan', 'India'],\n",
    "    'UZ': ['Uzbekistan'],\n",
    "    'VI': ['Vietnam'],\n",
    "    'XH': ['South Africa'],\n",
    "    'YI': ['Worldwide'],  # Yiddish is spoken by Jewish communities worldwide.\n",
    "    'YO': ['Nigeria', 'Benin'],\n",
    "    'ZH': ['China', 'Taiwan', 'Singapore', 'Malaysia'],\n",
    "    'ZU': ['South Africa'],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Map language codes to countries\n",
    "languages_exploded['Countries'] = languages_exploded['languages'].map(lambda x: ', '.join(language_to_countries.get(x, ['Unknown'])))\n",
    "languages_exploded['Countries'] = languages_exploded['Countries'].fillna('Unknown')\n",
    "# Split the 'Countries' column into a list of countries\n",
    "languages_exploded['Countries'] = languages_exploded['Countries'].str.split(', ')\n",
    "# Explode the 'Countries' column\n",
    "languages_exploded = languages_exploded.explode('Countries')\n",
    "\n",
    "def get_language_name(lang_code):\n",
    "    # Check if lang_code is not a string or if it's NaN\n",
    "    if not isinstance(lang_code, str) or pd.isna(lang_code):\n",
    "        return \"en\"  # Return 'Unknown' or some other placeholder\n",
    "\n",
    "    # Convert the language code to lowercase to match the iso639 library's expected format\n",
    "    lang_code_lower = lang_code.lower()\n",
    "    try:\n",
    "        # Attempt to get the language name using the ISO 639-1 code\n",
    "        lang_name = languages.get(part1=lang_code_lower).name\n",
    "    except KeyError:\n",
    "        try:\n",
    "            # If the ISO 639-1 code lookup fails, try the ISO 639-2/T code\n",
    "            lang_name = languages.get(part2t=lang_code_lower).name\n",
    "        except KeyError:\n",
    "            try:\n",
    "                # If the ISO 639-2/T code lookup also fails, try the ISO 639-2/B code\n",
    "                lang_name = languages.get(part2b=lang_code_lower).name\n",
    "            except KeyError:\n",
    "                # If none of the lookups are successful, return the original code\n",
    "                lang_name = lang_code  # Keeping the original case for visibility\n",
    "    return lang_name\n",
    "\n",
    "# Apply the function to translate language codes to names\n",
    "languages_exploded['language_name'] = languages_exploded['languages'].apply(get_language_name)\n",
    "\n",
    "\n",
    "\n",
    "# Categorizing Numerical Data\n",
    "bins = [0, 50000000, 200000000, float('inf')]\n",
    "labels = ['Small', 'Medium', 'Large']\n",
    "\n",
    "\n",
    "# Function to convert binary values to 'free' or 'paid'\n",
    "def free_convert_to_category(value):\n",
    "    if value == 1:\n",
    "        return 'free'\n",
    "    else:\n",
    "        return 'paid'\n",
    "\n",
    "## App age categorization\n",
    "def categorize_app_age(days):\n",
    "    if days <= 30:\n",
    "        return 'Brand New'\n",
    "    elif days <= 90:\n",
    "        return 'Recently Launched'\n",
    "    elif days <= 365:\n",
    "        return 'Established'\n",
    "    elif days <= 1095:\n",
    "        return 'Mature'\n",
    "    else:\n",
    "        return 'Very Mature'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Define categories based on percentiles\n",
    "def price_category(price):\n",
    "    if price == 0:\n",
    "        return 'Free'\n",
    "    elif price <= percentilesPrice[0.25]:\n",
    "        return 'Low'\n",
    "    elif price <= percentilesPrice[0.50]:\n",
    "        return 'Medium'\n",
    "    elif price <= percentilesPrice[0.75]:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'    \n",
    "        \n",
    "\n",
    "## Update frequency categorization\n",
    "def categorize_update_frequency(days_since_last_update):\n",
    "    if days_since_last_update <= 30:\n",
    "        return 'Very Recent Updates'\n",
    "    elif days_since_last_update <= 90:\n",
    "        return 'Recently Updated'\n",
    "    elif days_since_last_update <= 180:\n",
    "        return 'Moderately Updated'\n",
    "    elif days_since_last_update <= 365:\n",
    "        return 'Rarely Updated'\n",
    "    else:\n",
    "        return 'Stale'\n",
    "\n",
    "\n",
    "\n",
    "# Process reviews\n",
    "df['Sentiment_Category'] = df['reviews'].apply(compute_sentiment_category_mbert)\n",
    "\n",
    "# Update frequency calculation\n",
    "df['update_frequency'] = df['days_since_last_update'].apply(categorize_update_frequency)\n",
    "\n",
    "## Apply the categorization function to the 'price' column\n",
    "percentilesPrice = df['price'].quantile([0.25, 0.50, 0.75])\n",
    "df['price_category'] = df['price'].apply(price_category)\n",
    "\n",
    "## Apply the categorization function to the 'app_age' column\n",
    "df['app_age_category'] = df['app_age'].apply(lambda days: categorize_app_age(days))\n",
    "\n",
    "## Apply the categorization function to the 'file_size' column\n",
    "df['file_size_category'] = pd.cut(df['size'], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "# Aggregate Languages and Genres\n",
    "language_counts = df.filter(regex='^lang_').sum().reset_index()\n",
    "genre_counts = df.filter(regex='^_').sum().reset_index()\n",
    "\n",
    "# Remove '_' prefix and rename columns\n",
    "genre_counts['index'] = genre_counts['index'].str.replace('^_', '', regex=True)\n",
    "genre_counts.columns = ['Genre', 'Number of Apps']\n",
    "\n",
    "# Remove 'lang_' prefix and rename columns\n",
    "language_counts['index'] = language_counts['index'].str.replace('lang_', '', regex=True)\n",
    "language_counts.columns = ['Language', 'Number of Apps']\n",
    "\n",
    "\n",
    "# Creating a relational table for device support\n",
    "device_support = df.melt(id_vars=['appId'], value_vars=['supports_iPhone', 'supports_iPad', 'supports_Mac'], var_name='Device', value_name='Supported')\n",
    "device_support = device_support[device_support['Supported'] == 1].drop('Supported', axis=1)\n",
    "device_support.to_csv('AppStore_Device_Support.csv', index=False)\n",
    "\n",
    "\n",
    "# Apply the function to the 'free' column\n",
    "df['free'] = df['free'].apply(free_convert_to_category)\n",
    "\n",
    "\n",
    "# Rename columns for clarity\n",
    "language_counts.columns = ['Language', 'Number of Apps']\n",
    "genre_counts.columns = ['Genre', 'Number of Apps']\n",
    "\n",
    "# Preview the aggregated language data\n",
    "print(language_counts.head())\n",
    "print('\\n')\n",
    "# Preview the aggregated genre data\n",
    "print(genre_counts.head())\n",
    "\n",
    "# Device support aggregation\n",
    "device_support_counts = df[['supports_iPhone', 'supports_iPad', 'supports_Mac']].sum().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "device_support_counts.columns = ['Device Type', 'Number of Apps']\n",
    "\n",
    "# Convert device type names to more readable format if necessary\n",
    "# Example: You can manually rename each type for clarity\n",
    "device_support_counts['Device Type'] = device_support_counts['Device Type'].replace({\n",
    "    'supports_iPhone': 'iPhone',\n",
    "    'supports_iPad': 'iPad',\n",
    "    'supports_Mac': 'Mac'\n",
    "})\n",
    "\n",
    "# Preview the device support data\n",
    "print(device_support_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final DataFrame Cleanup and Saving the Cleaned Data\n",
    "columns_to_remove = [\n",
    "    'id', '', 'description', 'icon', 'genreIds', 'primaryGenreId',\n",
    "    'requiredOsVersion', 'releaseNotes', 'version', 'developerid', 'developerUrl',\n",
    "    'screenshots', 'ipadScreenshots', 'appletvScreenshots',\n",
    "    'languages', 'genres', 'supportedDevices', 'currency', 'developerId', 'reviews', \n",
    "]\n",
    "df.drop(columns_to_remove, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('AppStoreOutput_cleaned.csv', index=False, sep=',', encoding='utf-8')\n",
    "languages_exploded.to_csv('AppStore_Languages.csv', index=False)\n",
    "genres_exploded.to_csv('AppStore_Genres.csv', index=False)\n",
    "\n",
    "# Save the results to separate CSV files\n",
    "bigram_freq_df.to_csv('AppStore_Bigrams.csv', index=False)\n",
    "word_freq_df.to_csv('AppStore_Word_Frequencies.csv', index=False)\n",
    "print(\"Bigrams and word frequencies have been saved to CSV files.\")\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.fileids()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
